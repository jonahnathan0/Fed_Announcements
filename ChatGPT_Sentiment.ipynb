{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72f8be7-66f2-4322-9ab9-998cc78662fd",
   "metadata": {},
   "source": [
    "### ChatGPT Use Case Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4d541-abc4-4720-b75e-e31012fc31fb",
   "metadata": {},
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9329c15d-e4c2-4f30-aa0d-fa6d469d4b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sentiment_Rating\n",
      "0                -0.7\n",
      "1                -0.7\n",
      "2                -0.7\n",
      "3                -0.2\n",
      "4                -0.2\n",
      "..                ...\n",
      "195               0.1\n",
      "196              -0.1\n",
      "197              -0.1\n",
      "198               0.2\n",
      "199               0.1\n",
      "\n",
      "[200 rows x 1 columns]\n",
      "\n",
      "Total processed: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time  \n",
    "\n",
    "#client = OpenAI(api_key= 'secret key')\n",
    "\n",
    "\n",
    "folder_path = \"raw_data/announcements\"\n",
    "html_files = [f for f in os.listdir(folder_path) if f.endswith(\".html\")]\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    match = re.search(r\"monetary(\\d{8})\", filename)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(1), \"%Y%m%d\")\n",
    "    return None\n",
    "\n",
    "dated_files = [(extract_date_from_filename(f), f) for f in html_files]\n",
    "dated_files = [pair for pair in dated_files if pair[0] is not None]\n",
    "dated_files.sort()  \n",
    "\n",
    "ratings = []\n",
    "\n",
    "for date, filename in dated_files:\n",
    "    try:\n",
    "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f, 'html.parser')\n",
    "            fomc_text = soup.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a financial analyst specializing in monetary policy communications. Read the following FOMC announcement and answer the following questions:\n",
    "\n",
    "        1. What is the sentiment at the beginning of the announcement? (Bearish, Neutral, Bullish)\n",
    "        2. Provide a final numerical sentiment rating to the entire document based on your analysis of the tone shift and sentiment throughout, using this scale:\n",
    "            -1 = Bearish\n",
    "             0 = Neutral\n",
    "             1 = Bullish\n",
    "             The rating can be a decimal (e.g., -0.9,-0.8,-.0.7,-0.6,-0.5, -0.4,-0.3,-0.2,-0.1, 0.1, 0.2, 0.3, 0.4,0.5,0.6,0.7,0.8, 0.9, etc.). \n",
    "\n",
    "        Just output the rating number without any explanation.\n",
    "\n",
    "        FOMC Text:\n",
    "        {fomc_text}\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=500,\n",
    "            temperature=0.4\n",
    "        )\n",
    "\n",
    "        response_text = response.choices[0].message.content\n",
    "        match = re.search(r\"2\\.\\s*(-?\\d*\\.\\d+|\\d+)\", response_text)\n",
    "\n",
    "        if match:\n",
    "            extracted_rating = float(match.group(1))\n",
    "        else:\n",
    "            extracted_rating = None  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        extracted_rating = None\n",
    "\n",
    "    ratings.append(extracted_rating)\n",
    "    time.sleep(1.2)  \n",
    "\n",
    "statements_chat_df = pd.DataFrame(ratings, columns=[\"Sentiment_Rating\"])\n",
    "print(statements_chat_df)\n",
    "print(f\"\\nTotal processed: {len(statements_chat_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbb64b9b-a8b6-48b7-aa7f-af8724100b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_chat_df_filled = statements_chat_df.copy()\n",
    "statements_chat_df_filled = statements_chat_df_filled.fillna(0)\n",
    "statements_chat_df_filled.insert(0, 'meeting_id', range(1, len(statements_chat_df_filled) + 1))\n",
    "statements_chat_df_filled['document_type'] = 'statement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9df2c984-4d8b-49b8-b1ff-5d91e029511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_chat_df_filled.to_csv('raw_data/statements_chat_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef211e7b-e1ca-4bc3-a0c0-82a5a1ad9a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing fomcminutes20071031.html: 'utf-8' codec can't decode byte 0x9a in position 7588: invalid start byte\n",
      "Error processing fomcminutes20080130.html: 'utf-8' codec can't decode byte 0x93 in position 61922: invalid start byte\n",
      "Error processing fomcminutes20091216.html: 'utf-8' codec can't decode byte 0x92 in position 43345: invalid start byte\n",
      "Error processing fomcminutes20100127.html: 'utf-8' codec can't decode byte 0x97 in position 51191: invalid start byte\n",
      "Error processing fomcminutes20100428.html: 'utf-8' codec can't decode byte 0x9a in position 8700: invalid start byte\n",
      "Error processing fomcminutes20100623.html: 'utf-8' codec can't decode byte 0x96 in position 60390: invalid start byte\n",
      "Error processing fomcminutes20110126.html: 'utf-8' codec can't decode byte 0x96 in position 35385: invalid start byte\n",
      "Error processing fomcminutes20110427.html: 'utf-8' codec can't decode byte 0x96 in position 21699: invalid start byte\n",
      "Error processing fomcminutes20110809.html: 'utf-8' codec can't decode byte 0x96 in position 10746: invalid start byte\n",
      "Error processing fomcminutes20110921.html: 'utf-8' codec can't decode byte 0x96 in position 32473: invalid start byte\n",
      "Error processing fomcminutes20111213.html: 'utf-8' codec can't decode byte 0x96 in position 10250: invalid start byte\n",
      "     Sentiment_Rating\n",
      "0                 0.1\n",
      "1                 0.2\n",
      "2                -0.5\n",
      "3                 0.2\n",
      "4                 0.2\n",
      "..                ...\n",
      "195               0.1\n",
      "196               0.2\n",
      "197               0.2\n",
      "198               NaN\n",
      "199               0.1\n",
      "\n",
      "[200 rows x 1 columns]\n",
      "\n",
      "Total processed: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time  \n",
    "\n",
    "#client = OpenAI(api_key= 'secret key')\n",
    "\n",
    "folder_path = \"raw_data/intermeeting\"\n",
    "html_files = [f for f in os.listdir(folder_path) if f.endswith(\".html\")]\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    match = re.search(r\"fomcminutes(\\d{8})\", filename)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(1), \"%Y%m%d\")\n",
    "    return None\n",
    "\n",
    "dated_files = [(extract_date_from_filename(f), f) for f in html_files]\n",
    "dated_files = [pair for pair in dated_files if pair[0] is not None]\n",
    "dated_files.sort()  \n",
    "\n",
    "ratings = []\n",
    "\n",
    "for date, filename in dated_files:\n",
    "    try:\n",
    "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f, 'html.parser')\n",
    "            fomc_text = soup.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        if len(fomc_text) > 32000:\n",
    "            fomc_text = fomc_text[:32000]\n",
    "            \n",
    "        prompt = f\"\"\"\n",
    "        You are a financial analyst specializing in monetary policy communications. Read the following FOMC announcement and answer the following questions:\n",
    "\n",
    "        1. What is the sentiment at the beginning of the announcement? (Bearish, Neutral, Bullish)\n",
    "        2. Provide a final numerical sentiment rating to the entire document based on your analysis of the tone shift and sentiment throughout, using this scale:\n",
    "            -1 = Bearish\n",
    "             0 = Neutral\n",
    "             1 = Bullish\n",
    "             The rating can be a decimal (e.g., -0.9,-0.8,-.0.7,-0.6,-0.5, -0.4,-0.3,-0.2,-0.1, 0.1, 0.2, 0.3, 0.4,0.5,0.6,0.7,0.8, 0.9, etc.). \n",
    "\n",
    "        Just output the rating number without any explanation.\n",
    "\n",
    "        FOMC Text:\n",
    "        {fomc_text}\n",
    "        \"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=500,\n",
    "            temperature=0.4\n",
    "        )\n",
    "\n",
    "        response_text = response.choices[0].message.content\n",
    "        match = re.search(r\"2\\.\\s*(-?\\d*\\.\\d+|\\d+)\", response_text)\n",
    "\n",
    "        if match:\n",
    "            extracted_rating = float(match.group(1))\n",
    "        else:\n",
    "            extracted_rating = None  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        extracted_rating = None\n",
    "\n",
    "    ratings.append(extracted_rating)\n",
    "    time.sleep(1.2)  \n",
    "\n",
    "intermeeting_chat_df = pd.DataFrame(ratings, columns=[\"Sentiment_Rating\"])\n",
    "print(intermeeting_chat_df)\n",
    "print(f\"\\nTotal processed: {len(intermeeting_chat_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "742b8274-e7bd-4ccd-b12a-440de3363eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermeeting_chat_df_filled = intermeeting_chat_df.copy()\n",
    "intermeeting_chat_df_filled = intermeeting_chat_df_filled.fillna(0)\n",
    "intermeeting_chat_df_filled.insert(0, 'meeting_id', range(1, len(intermeeting_chat_df_filled) + 1))\n",
    "intermeeting_chat_df_filled['document_type'] = 'intermeeting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a1636ad-ede5-4a53-82d3-3c383d111d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermeeting_chat_df_filled.to_csv('raw_data/intermeeting_chat_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe0567-497a-412e-8117-737feb90b285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4720ee-2056-4c01-8b4f-0e84dafdf225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
