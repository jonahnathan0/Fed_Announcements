{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb2285-6909-45de-88e3-7bcc682f6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Our"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31baf4f8-8077-43e1-a54f-22e2e359d01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/fd_cpcmx35x03xwkvsfgw9kc0000gn/T/ipykernel_14430/1738463436.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dates_statements['Statement Date'] = pd.to_datetime(dates_statements['Statement Date'], errors='coerce')\n",
      "/var/folders/hl/fd_cpcmx35x03xwkvsfgw9kc0000gn/T/ipykernel_14430/1738463436.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dates_intermeetings['Intermeeting Date'] = pd.to_datetime(dates_intermeetings['Intermeeting Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load Dates for Statements & Intermeetings\n",
    "dates_statements = pd.read_csv('dates/dates_updated.csv')\n",
    "dates_statements['Statement Date'] = pd.to_datetime(dates_statements['Statement Date'], errors='coerce')\n",
    "dates_statements['document_type'] = 'statement'\n",
    "\n",
    "dates_intermeetings = pd.read_csv('dates/dates_updated.csv')\n",
    "dates_intermeetings['Intermeeting Date'] = pd.to_datetime(dates_intermeetings['Intermeeting Date'], errors='coerce')\n",
    "dates_intermeetings['document_type'] = 'intermeeting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a94b8f-c4b9-4028-b554-046ade653286",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    '^GSPC', '^IXIC', '^DJI', '^RUT', '^W5000',\n",
    "    'XLF', 'XLRE', 'XLU', 'XLY', 'XLP',\n",
    "    'XLE', 'XLV', 'XLI', 'XLB', 'XLK', 'XLC',\n",
    "    '^IRX', '^TNX'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb0aee3-dd00-415c-9721-59531f904099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/fd_cpcmx35x03xwkvsfgw9kc0000gn/T/ipykernel_14430/484069958.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dates['Statement Date'] = pd.to_datetime(dates['Statement Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dates = pd.read_csv('dates/dates_updated.csv')\n",
    "dates['Statement Date'] = pd.to_datetime(dates['Statement Date'])\n",
    "dates['document_type'] = 'statement' \n",
    "\n",
    "tickers = [\n",
    "    '^GSPC',     # S&P 500\n",
    "    '^IXIC',     # NASDAQ Composite\n",
    "    '^DJI',      # Dow Jones Industrial Average\n",
    "    '^RUT',      # Russell 2000\n",
    "    '^W5000',    # Wilshire 5000\n",
    "    'XLF',       # Financials Sector (ETF)\n",
    "    'XLRE',      # Real Estate Sector (ETF)\n",
    "    'XLU',       # Utilities Sector (ETF)\n",
    "    'XLY',       # Consumer Discretionary Sector (ETF)\n",
    "    'XLP',       # Consumer Staples Sector (ETF)\n",
    "    'XLE',       # Energy Sector (ETF)\n",
    "    'XLV',       # Healthcare Sector (ETF)\n",
    "    'XLI',       # Industrials Sector (ETF)\n",
    "    'XLB',       # Materials Sector (ETF)\n",
    "    'XLK',       # Information Technology Sector (ETF)\n",
    "    'XLC',       # Communication Services Sector (ETF)\n",
    "    '^IRX',      # Three-month Treasury Bill Yield\n",
    "    '^TNX',      # Ten-year Treasury Yield\n",
    "]\n",
    "\n",
    "start_date = dates['Statement Date'].min() - pd.Timedelta(days=15)\n",
    "end_date = dates['Statement Date'].max() + pd.Timedelta(days=15)\n",
    "\n",
    "all_indices_data = {}\n",
    "for ticker in tickers:\n",
    "    #print(f\"Downloading data for {ticker}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data.columns = data.columns.get_level_values(0)\n",
    "    data['return'] = data['Close'].pct_change()\n",
    "    all_indices_data[ticker] = data[['return']].dropna()\n",
    "    #print(f\"Data for {ticker} downloaded.\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for index, row_fomc in dates.iterrows():\n",
    "    date = row_fomc['Statement Date']\n",
    "    document_type = row_fomc['document_type']\n",
    "    for ticker in tickers:\n",
    "        row = {'announcement_date': date, 'ticker': ticker, 'document_type': document_type} \n",
    "        for t in range(-15, 16):\n",
    "            target_date = date + pd.Timedelta(days=t)\n",
    "            if target_date in all_indices_data[ticker].index:\n",
    "                row[f'T{t:+}'] = all_indices_data[ticker].loc[target_date, 'return']\n",
    "            else:\n",
    "                row[f'T{t:+}'] = pd.NA\n",
    "        rows.append(row)\n",
    "\n",
    "statements_df = pd.DataFrame(rows)\n",
    "\n",
    "column_order = ['announcement_date', 'ticker', 'document_type'] + [f'T{t:+}' for t in range(-15, 16)]\n",
    "statements_df = statements_df[column_order]\n",
    "\n",
    "statements_df\n",
    "\n",
    "statements_df.to_csv('raw_data/statement_prices.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a44db61-45cf-45d7-a01e-776955054f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/fd_cpcmx35x03xwkvsfgw9kc0000gn/T/ipykernel_14430/3896584411.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dates['Intermeeting Date'] = pd.to_datetime(dates['Intermeeting Date'])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dates = pd.read_csv('dates/dates_updated.csv')\n",
    "dates['Intermeeting Date'] = pd.to_datetime(dates['Intermeeting Date'])\n",
    "dates['document_type'] = 'intermeeting' \n",
    "\n",
    "tickers = [\n",
    "    '^GSPC',     # S&P 500\n",
    "    '^IXIC',     # NASDAQ Composite\n",
    "    '^DJI',      # Dow Jones Industrial Average\n",
    "    '^RUT',      # Russell 2000\n",
    "    '^W5000',    # Wilshire 5000\n",
    "    'XLF',       # Financials Sector (ETF)\n",
    "    'XLRE',      # Real Estate Sector (ETF)\n",
    "    'XLU',       # Utilities Sector (ETF)\n",
    "    'XLY',       # Consumer Discretionary Sector (ETF)\n",
    "    'XLP',       # Consumer Staples Sector (ETF)\n",
    "    'XLE',       # Energy Sector (ETF)\n",
    "    'XLV',       # Healthcare Sector (ETF)\n",
    "    'XLI',       # Industrials Sector (ETF)\n",
    "    'XLB',       # Materials Sector (ETF)\n",
    "    'XLK',       # Information Technology Sector (ETF)\n",
    "    'XLC',       # Communication Services Sector (ETF)\n",
    "    '^IRX',      # Three-month Treasury Bill Yield\n",
    "    '^TNX',      # Ten-year Treasury Yield\n",
    "]\n",
    "\n",
    "start_date = dates['Intermeeting Date'].min() - pd.Timedelta(days=15)\n",
    "end_date = dates['Intermeeting Date'].max() + pd.Timedelta(days=15)\n",
    "\n",
    "all_indices_data = {}\n",
    "for ticker in tickers:\n",
    "    #print(f\"Downloading data for {ticker}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data.columns = data.columns.get_level_values(0)\n",
    "    data['return'] = data['Close'].pct_change()\n",
    "    all_indices_data[ticker] = data[['return']].dropna()\n",
    "    #print(f\"Data for {ticker} downloaded.\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for index, row_fomc in dates.iterrows():\n",
    "    date = row_fomc['Intermeeting Date']\n",
    "    document_type = row_fomc['document_type']\n",
    "    for ticker in tickers:\n",
    "        row = {'announcement_date': date, 'ticker': ticker, 'document_type': document_type} \n",
    "        for t in range(-15, 16):\n",
    "            target_date = date + pd.Timedelta(days=t)\n",
    "            if target_date in all_indices_data[ticker].index:\n",
    "                row[f'T{t:+}'] = all_indices_data[ticker].loc[target_date, 'return']\n",
    "            else:\n",
    "                row[f'T{t:+}'] = pd.NA\n",
    "        rows.append(row)\n",
    "\n",
    "intermeeting_df = pd.DataFrame(rows)\n",
    "\n",
    "column_order = ['announcement_date', 'ticker', 'document_type'] + [f'T{t:+}' for t in range(-15, 16)]\n",
    "intermeeting_df = intermeeting_df[column_order]\n",
    "\n",
    "intermeeting_df\n",
    "\n",
    "intermeeting_df.to_csv('raw_data/intermeeting_prices.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25ddb14-de4b-413e-b460-a7aed6505bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([statements_df, intermeeting_df], ignore_index=True)\n",
    "combined_df = combined_df.dropna(subset=['announcement_date'])\n",
    "combined_df = combined_df.sort_values(by='announcement_date').reset_index(drop=True)\n",
    "combined_df['meeting_id'] = combined_df['announcement_date'].rank(method='dense').astype(int)\n",
    "combined_df = combined_df[['meeting_id'] + [col for col in combined_df.columns if col != 'meeting_id']]\n",
    "combined_df.to_csv('raw_data/combined_dates.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60068fe3-7383-4b03-a7e8-d60cc291ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meeting_id', 'announcement_date', 'ticker', 'document_type', 'T-15', 'T-14', 'T-13', 'T-12', 'T-11', 'T-10', 'T-9', 'T-8', 'T-7', 'T-6', 'T-5', 'T-4', 'T-3', 'T-2', 'T-1', 'T+0', 'T+1', 'T+2', 'T+3', 'T+4', 'T+5', 'T+6', 'T+7', 'T+8', 'T+9', 'T+10', 'T+11', 'T+12', 'T+13', 'T+14', 'T+15']\n",
      "All index data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Combined Returns Data\n",
    "combined_returns = pd.read_csv('raw_data/combined_dates.csv')\n",
    "print(combined_returns.columns.tolist())\n",
    "\n",
    "# Define T-10 to T+10 columns\n",
    "t_columns = [f'T{t}' if t < 0 else f'T+{t}' if t > 0 else 'T0' for t in range(-10, 11)]\n",
    "\n",
    "# Build dictionary by ticker\n",
    "all_indices_data = {}\n",
    "\n",
    "for ticker in combined_returns['ticker'].unique():\n",
    "    ticker_data = combined_returns[combined_returns['ticker'] == ticker]\n",
    "    ticker_data = ticker_data.set_index('announcement_date')  # Set date as index\n",
    "    ticker_data.index = pd.to_datetime(ticker_data.index)  # Ensure datetime index\n",
    "    all_indices_data[ticker] = ticker_data\n",
    "\n",
    "print(\"All index data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d071595-2e70-4a7d-b8c7-553a61c73361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "announcement_date\n",
       "2000-02-02   -0.003428\n",
       "2000-03-21    0.021264\n",
       "2000-03-23    0.023297\n",
       "2000-05-16    0.011731\n",
       "2000-05-18    0.000700\n",
       "                ...   \n",
       "2025-01-08    0.002512\n",
       "2025-01-29   -0.003051\n",
       "2025-02-19    0.001599\n",
       "2025-03-19    0.009219\n",
       "2025-04-09    0.078704\n",
       "Name: T+0, Length: 411, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_indices_data['^DJI']['T+0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c227450-58c8-4cb3-991c-1d08dda02479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your get_trading_window function\n",
    "def get_trading_window(trading_dates, fed_date, returns_series, window=10):\n",
    "    try:\n",
    "        fed_idx = trading_dates.get_loc(fed_date)\n",
    "    except KeyError:\n",
    "        idx_array = trading_dates.get_indexer([fed_date], method='ffill')\n",
    "        fed_idx = idx_array[0]\n",
    "        if fed_idx == -1:\n",
    "            return None\n",
    "\n",
    "    if fed_idx < 0 or fed_idx >= len(returns_series):\n",
    "        return None\n",
    "\n",
    "    result = {}\n",
    "    for t in range(-window, 0):\n",
    "        if 0 <= fed_idx + t < len(returns_series):\n",
    "            result[f'T{t:+}'] = returns_series.iloc[fed_idx + t]\n",
    "        else:\n",
    "            result[f'T{t:+}'] = pd.NA\n",
    "    if 0 <= fed_idx < len(returns_series):\n",
    "        result['T0'] = returns_series.iloc[fed_idx]\n",
    "    else:\n",
    "        result['T0'] = pd.NA\n",
    "    for t in range(1, window + 1):\n",
    "        if 0 <= fed_idx + t < len(returns_series):\n",
    "            result[f'T{t:+}'] = returns_series.iloc[fed_idx + t]\n",
    "        else:\n",
    "            result[f'T{t:+}'] = pd.NA\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c5beac-63de-4299-ad19-99dc11eb0745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement prices processed.\n"
     ]
    }
   ],
   "source": [
    "# Process Statement Prices\n",
    "rows = []\n",
    "\n",
    "for idx, row_fomc in dates_statements.iterrows():\n",
    "    date = row_fomc['Statement Date']\n",
    "    document_type = row_fomc['document_type']\n",
    "\n",
    "    for ticker in all_indices_data.keys():\n",
    "        ticker_data = all_indices_data[ticker]\n",
    "\n",
    "        if date not in ticker_data.index:\n",
    "            continue  # skip if no data\n",
    "\n",
    "        row = {'announcement_date': date, 'ticker': ticker, 'document_type': document_type}\n",
    "\n",
    "        available_returns = ticker_data.loc[date]\n",
    "\n",
    "        # Find valid pre-event returns\n",
    "        pre_event_returns = []\n",
    "        for t in range(-15, 0):\n",
    "            col_name = f'T{t}'\n",
    "            if col_name in available_returns and pd.notna(available_returns[col_name]):\n",
    "                pre_event_returns.append((t, available_returns[col_name]))\n",
    "            if len(pre_event_returns) == 10:\n",
    "                break\n",
    "\n",
    "        # Find valid post-event returns\n",
    "        post_event_returns = []\n",
    "        for t in range(1, 16):\n",
    "            col_name = f'T+{t}'\n",
    "            if col_name in available_returns and pd.notna(available_returns[col_name]):\n",
    "                post_event_returns.append((t, available_returns[col_name]))\n",
    "            if len(post_event_returns) == 10:\n",
    "                break\n",
    "\n",
    "        # Event day (T0)\n",
    "        t0_value = available_returns.get('T+0', pd.NA)\n",
    "\n",
    "        # Always create full structure: T-10 to T-1, T0, T+1 to T+10\n",
    "        for i in range(-10, 0):\n",
    "            if len(pre_event_returns) >= abs(i):\n",
    "                row[f'T{i}'] = pre_event_returns[i + 10 - 1][1]  # -10 is idx 0\n",
    "            else:\n",
    "                row[f'T{i}'] = pd.NA\n",
    "\n",
    "        row['T0'] = t0_value\n",
    "\n",
    "        for i in range(1, 11):\n",
    "            if len(post_event_returns) >= i:\n",
    "                row[f'T+{i}'] = post_event_returns[i - 1][1]\n",
    "            else:\n",
    "                row[f'T+{i}'] = pd.NA\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "statements_df = pd.DataFrame(rows)\n",
    "\n",
    "column_order = ['announcement_date', 'ticker', 'document_type'] + [f'T{t}' if t < 0 else f'T+{t}' if t > 0 else 'T0' for t in range(-10, 11)]\n",
    "for col in column_order:\n",
    "    if col not in statements_df.columns:\n",
    "        statements_df[col] = pd.NA\n",
    "statements_df = statements_df[column_order]\n",
    "\n",
    "print(\"Statement prices processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0dcf34e-698b-4cbd-bfd7-77680d5dca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermeeting prices processed.\n"
     ]
    }
   ],
   "source": [
    "# Process Intermeeting Prices\n",
    "rows = []\n",
    "\n",
    "for idx, row_fomc in dates_intermeetings.iterrows():\n",
    "    date = row_fomc['Intermeeting Date']\n",
    "    document_type = row_fomc['document_type']\n",
    "\n",
    "    for ticker in all_indices_data.keys():\n",
    "        ticker_data = all_indices_data[ticker]\n",
    "\n",
    "        if date not in ticker_data.index:\n",
    "            continue  # skip if no data\n",
    "\n",
    "        row = {'announcement_date': date, 'ticker': ticker, 'document_type': document_type}\n",
    "\n",
    "        available_returns = ticker_data.loc[date]\n",
    "\n",
    "        # Find valid pre-event returns\n",
    "        pre_event_returns = []\n",
    "        for t in range(-15, 0):\n",
    "            col_name = f'T{t}'\n",
    "            if col_name in available_returns.index and pd.notna(available_returns[col_name]):\n",
    "                pre_event_returns.append((t, available_returns[col_name]))\n",
    "            if len(pre_event_returns) == 10:\n",
    "                break\n",
    "\n",
    "        # Find valid post-event returns\n",
    "        post_event_returns = []\n",
    "        for t in range(1, 16):\n",
    "            col_name = f'T+{t}'\n",
    "            if col_name in available_returns.index and pd.notna(available_returns[col_name]):\n",
    "                post_event_returns.append((t, available_returns[col_name]))\n",
    "            if len(post_event_returns) == 10:\n",
    "                break\n",
    "\n",
    "        # Event day (T0)\n",
    "        t0_value = available_returns.get('T+0', pd.NA)\n",
    "\n",
    "        # Always create full structure: T-10 to T-1\n",
    "        for i in range(-10, 0):\n",
    "            idx = abs(i) - 1\n",
    "            if idx < len(pre_event_returns):\n",
    "                row[f'T{i}'] = pre_event_returns[idx][1]\n",
    "            else:\n",
    "                row[f'T{i}'] = pd.NA\n",
    "        \n",
    "        # Event day\n",
    "        row['T0'] = t0_value\n",
    "        \n",
    "        # T+1 to T+10\n",
    "        for i in range(1, 11):\n",
    "            idx = i - 1\n",
    "            if idx < len(post_event_returns):\n",
    "                row[f'T+{i}'] = post_event_returns[idx][1]\n",
    "            else:\n",
    "                row[f'T+{i}'] = pd.NA\n",
    "\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "intermeeting_df = pd.DataFrame(rows)\n",
    "\n",
    "column_order = ['announcement_date', 'ticker', 'document_type'] + [f'T{t}' if t < 0 else f'T+{t}' if t > 0 else 'T0' for t in range(-10, 11)]\n",
    "for col in column_order:\n",
    "    if col not in intermeeting_df.columns:\n",
    "        intermeeting_df[col] = pd.NA\n",
    "intermeeting_df = intermeeting_df[column_order]\n",
    "\n",
    "print(\"Intermeeting prices processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7addf673-d95a-4201-8bfd-f26e3a63b7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>announcement_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>document_type</th>\n",
       "      <th>T-10</th>\n",
       "      <th>T-9</th>\n",
       "      <th>T-8</th>\n",
       "      <th>T-7</th>\n",
       "      <th>T-6</th>\n",
       "      <th>T-5</th>\n",
       "      <th>...</th>\n",
       "      <th>T+1</th>\n",
       "      <th>T+2</th>\n",
       "      <th>T+3</th>\n",
       "      <th>T+4</th>\n",
       "      <th>T+5</th>\n",
       "      <th>T+6</th>\n",
       "      <th>T+7</th>\n",
       "      <th>T+8</th>\n",
       "      <th>T+9</th>\n",
       "      <th>T+10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>statement</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>-0.002912</td>\n",
       "      <td>-0.027634</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>-0.020815</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>-0.010256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>XLY</td>\n",
       "      <td>statement</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>-0.013585</td>\n",
       "      <td>-0.020656</td>\n",
       "      <td>-0.037318</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.021158</td>\n",
       "      <td>0.022753</td>\n",
       "      <td>-0.016685</td>\n",
       "      <td>-0.00905</td>\n",
       "      <td>-0.014269</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>-0.03908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>statement</td>\n",
       "      <td>0.02833</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>-0.032894</td>\n",
       "      <td>0.017414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033633</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.018291</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>-0.014514</td>\n",
       "      <td>0.02805</td>\n",
       "      <td>-0.020104</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.001556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>^DJI</td>\n",
       "      <td>statement</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>-0.006173</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.008773</td>\n",
       "      <td>-0.021645</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>-0.004507</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>-0.023585</td>\n",
       "      <td>-0.00519</td>\n",
       "      <td>-0.020521</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>-0.014618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>^RUT</td>\n",
       "      <td>statement</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>-0.020583</td>\n",
       "      <td>-0.002601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>-0.002772</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>-0.009424</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.01392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>^IRX</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>-0.004283</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007332</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>-0.004272</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>^TNX</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>0.04266</td>\n",
       "      <td>-0.017263</td>\n",
       "      <td>-0.033603</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>-0.021196</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>0.022531</td>\n",
       "      <td>-0.028711</td>\n",
       "      <td>-0.009395</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>0.01262</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>-0.003632</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>-0.058174</td>\n",
       "      <td>-0.059681</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043075</td>\n",
       "      <td>0.020574</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.030673</td>\n",
       "      <td>-0.00127</td>\n",
       "      <td>-0.025515</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>XLE</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>-0.006475</td>\n",
       "      <td>-0.091999</td>\n",
       "      <td>-0.078508</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065323</td>\n",
       "      <td>0.024812</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>-0.026135</td>\n",
       "      <td>0.02545</td>\n",
       "      <td>-0.001843</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>XLY</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>-0.011817</td>\n",
       "      <td>-0.043135</td>\n",
       "      <td>-0.0604</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039071</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>-0.024669</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>-0.026699</td>\n",
       "      <td>0.031643</td>\n",
       "      <td>0.022346</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7398 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meeting_id announcement_date ticker document_type      T-10       T-9  \\\n",
       "0              1        2000-02-02  ^GSPC     statement  0.010628  0.000522   \n",
       "1              1        2000-02-02    XLY     statement  0.036186 -0.002086   \n",
       "2              1        2000-02-02  ^IXIC     statement   0.02833  0.004958   \n",
       "3              1        2000-02-02   ^DJI     statement  0.009188 -0.006173   \n",
       "4              1        2000-02-02   ^RUT     statement  0.015154  0.012776   \n",
       "...          ...               ...    ...           ...       ...       ...   \n",
       "7393         408        2025-04-09   ^IRX  intermeeting -0.001203 -0.007168   \n",
       "7394         408        2025-04-09   ^TNX  intermeeting   0.04266 -0.017263   \n",
       "7395         408        2025-04-09  ^IXIC  intermeeting  0.000992 -0.058174   \n",
       "7396         408        2025-04-09    XLE  intermeeting -0.006475 -0.091999   \n",
       "7397         408        2025-04-09    XLY  intermeeting -0.011817 -0.043135   \n",
       "\n",
       "           T-8       T-7       T-6       T-5  ...       T+1       T+2  \\\n",
       "0    -0.007095 -0.002912 -0.027634  0.006065  ...  0.011248 -0.000421   \n",
       "1    -0.013585 -0.020656 -0.037318  0.006179  ...  0.003907 -0.001668   \n",
       "2     0.009207  0.010954 -0.032894  0.017414  ...  0.033633  0.007875   \n",
       "3    -0.012016 -0.008773 -0.021645  0.001973  ...  0.000931 -0.004507   \n",
       "4     0.013961  0.012631 -0.020583 -0.002601  ...  0.023025  0.007457   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "7393 -0.004283  0.000714  0.001669  0.001194  ... -0.007332  0.003812   \n",
       "7394 -0.033603  0.009625 -0.021196 -0.002115  ... -0.001364  0.022531   \n",
       "7395 -0.059681  0.008663  0.008706 -0.001368  ... -0.043075  0.020574   \n",
       "7396 -0.078508  0.001383  0.005886  0.011035  ... -0.065323  0.024812   \n",
       "7397   -0.0604  0.018996  0.010432  0.002132  ... -0.039071  0.009686   \n",
       "\n",
       "           T+3       T+4       T+5       T+6       T+7       T+8       T+9  \\\n",
       "0    -0.000091  0.012273 -0.020815  0.003627 -0.020969  0.002033  0.008713   \n",
       "1    -0.021158  0.022753 -0.016685  -0.00905 -0.014269  0.005211  0.002304   \n",
       "2     0.018291  0.024465 -0.014514   0.02805 -0.020104  0.005255  0.000502   \n",
       "3    -0.005291  0.004751 -0.023585  -0.00519 -0.020521  0.009077  0.018845   \n",
       "4     0.013073  0.009579 -0.002772  0.011586 -0.009424  0.005288  0.000556   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7393 -0.004272  0.001192  0.001905 -0.000713  0.001189  0.000713 -0.001187   \n",
       "7394 -0.028711 -0.009395 -0.010178   0.01262  0.016617 -0.003632 -0.000456   \n",
       "7395  0.006399 -0.000494 -0.030673  -0.00127 -0.025515  0.027063  0.025007   \n",
       "7396  0.003549 -0.001516  0.008223  0.022585 -0.026135   0.02545 -0.001843   \n",
       "7397  0.002899   -0.0072 -0.024669  0.006296 -0.026699  0.031643  0.022346   \n",
       "\n",
       "          T+10  \n",
       "0    -0.010256  \n",
       "1     -0.03908  \n",
       "2     0.001556  \n",
       "3    -0.014618  \n",
       "4      0.01392  \n",
       "...        ...  \n",
       "7393      <NA>  \n",
       "7394      <NA>  \n",
       "7395      <NA>  \n",
       "7396      <NA>  \n",
       "7397      <NA>  \n",
       "\n",
       "[7398 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([statements_df, intermeeting_df], ignore_index=True)\n",
    "combined_df = combined_df.dropna(subset=['announcement_date'])\n",
    "combined_df = combined_df.sort_values(by='announcement_date').reset_index(drop=True)\n",
    "combined_df['meeting_id'] = combined_df['announcement_date'].rank(method='dense').astype(int)\n",
    "combined_df = combined_df[['meeting_id'] + [col for col in combined_df.columns if col != 'meeting_id']]\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a8cc25-38d3-47dd-9491-2b19dc7f1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('raw_data/new_combined_dates.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
