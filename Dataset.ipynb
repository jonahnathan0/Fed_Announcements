{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135d6485-e2f5-4e5c-978b-ecf837863087",
   "metadata": {},
   "source": [
    "# Index Return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a351ce7-4b7a-4b7d-8035-44dd93bac618",
   "metadata": {},
   "source": [
    "- using yahoo finance for historical stock return data \n",
    "- going to need the following\n",
    "    - Dates of the announcement\n",
    "    - Index returns 10 days before the announcement\n",
    "    - Index returns the day of the announcement\n",
    "    - Index returns 10 days after the announcement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9370d44-768d-47a2-ba49-c69abc945813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ac69555-320a-4823-a3c6-2e19f250c3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/fd_cpcmx35x03xwkvsfgw9kc0000gn/T/ipykernel_90902/18165018.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fomc_statements['Date'] = pd.to_datetime(fomc_statements['Date'])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fomc_statements = pd.read_csv('dates/fomc_statements.csv')\n",
    "fomc_statements['Date'] = pd.to_datetime(fomc_statements['Date'])\n",
    "fomc_statements['document_type'] = 'statement' \n",
    "\n",
    "tickers = [\n",
    "    '^GSPC',     # S&P 500\n",
    "    '^IXIC',     # NASDAQ Composite\n",
    "    '^DJI',      # Dow Jones Industrial Average\n",
    "    '^RUT',      # Russell 2000\n",
    "    '^W5000',    # Wilshire 5000\n",
    "    'XLF',       # Financials Sector (ETF)\n",
    "    'XLRE',      # Real Estate Sector (ETF)\n",
    "    'XLU',       # Utilities Sector (ETF)\n",
    "    'XLY',       # Consumer Discretionary Sector (ETF)\n",
    "    'XLP',       # Consumer Staples Sector (ETF)\n",
    "    'XLE',       # Energy Sector (ETF)\n",
    "    'XLV',       # Healthcare Sector (ETF)\n",
    "    'XLI',       # Industrials Sector (ETF)\n",
    "    'XLB',       # Materials Sector (ETF)\n",
    "    'XLK',       # Information Technology Sector (ETF)\n",
    "    'XLC',       # Communication Services Sector (ETF)\n",
    "    '^IRX',      # Three-month Treasury Bill Yield\n",
    "    '^TNX',      # Ten-year Treasury Yield\n",
    "]\n",
    "\n",
    "start_date = fomc_statements['Date'].min() - pd.Timedelta(days=15)\n",
    "end_date = fomc_statements['Date'].max() + pd.Timedelta(days=15)\n",
    "\n",
    "all_indices_data = {}\n",
    "for ticker in tickers:\n",
    "    #print(f\"Downloading data for {ticker}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data.columns = data.columns.get_level_values(0)\n",
    "    data['return'] = data['Close'].pct_change()\n",
    "    all_indices_data[ticker] = data[['return']].dropna()\n",
    "    #print(f\"Data for {ticker} downloaded.\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for index, row_fomc in fomc_statements.iterrows():\n",
    "    date = row_fomc['Date']\n",
    "    document_type = row_fomc['document_type']\n",
    "    for ticker in tickers:\n",
    "        row = {'announcement_date': date, 'ticker': ticker, 'document_type': document_type} \n",
    "        for t in range(-15, 16):\n",
    "            target_date = date + pd.Timedelta(days=t)\n",
    "            if target_date in all_indices_data[ticker].index:\n",
    "                row[f'T{t:+}'] = all_indices_data[ticker].loc[target_date, 'return']\n",
    "            else:\n",
    "                row[f'T{t:+}'] = pd.NA\n",
    "        rows.append(row)\n",
    "\n",
    "final_df = pd.DataFrame(rows)\n",
    "\n",
    "column_order = ['announcement_date', 'ticker', 'document_type'] + [f'T{t:+}' for t in range(-15, 16)]\n",
    "final_df = final_df[column_order]\n",
    "\n",
    "final_df\n",
    "\n",
    "final_df.to_csv('raw_data/long_format_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9bfc0b-3a67-430e-9e2f-0ab41df4098d",
   "metadata": {},
   "source": [
    "### Problem\n",
    "Need to figure out how to get the days for around the intermeeting dates now because \n",
    "the dates in the html links are the same as the fed statements for those, which would cause a problem \n",
    "when getting return data.\n",
    "\n",
    "How to get around this?\n",
    "Find a dataset with the dates of the intermeeting or make our own (just manually do it - would take an hour maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a034c8d-01c6-4dab-b5fa-be359273d5b1",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e6016-5672-4489-90a0-59f7384cd814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad49a0-b3d6-4983-a636-ccfd2f6dae44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcf7fd-c74a-4a7b-a1d9-3af5ad8fd322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf3552-2719-447a-996a-f3b54de34f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229b378-ec08-4590-afe7-b3121ee7bc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22a562-53ed-4fab-80f4-43a26ed4e0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb79aa-8e72-4b98-95cf-f0f49a743aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
