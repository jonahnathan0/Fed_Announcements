{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135d6485-e2f5-4e5c-978b-ecf837863087",
   "metadata": {},
   "source": [
    "# Index Return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a351ce7-4b7a-4b7d-8035-44dd93bac618",
   "metadata": {},
   "source": [
    "- using yahoo finance for historical stock return data \n",
    "- going to need the following\n",
    "    - Dates of the announcement\n",
    "    - Index returns 10 days before the announcement\n",
    "    - Index returns the day of the announcement\n",
    "    - Index returns 10 days after the announcement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9370d44-768d-47a2-ba49-c69abc945813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ac69555-320a-4823-a3c6-2e19f250c3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/fd_cpcmx35x03xwkvsfgw9kc0000gn/T/ipykernel_9312/484069958.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dates['Statement Date'] = pd.to_datetime(dates['Statement Date'])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dates = pd.read_csv('dates/dates_updated.csv')\n",
    "dates['Statement Date'] = pd.to_datetime(dates['Statement Date'])\n",
    "dates['document_type'] = 'statement' \n",
    "\n",
    "tickers = [\n",
    "    '^GSPC',     # S&P 500\n",
    "    '^IXIC',     # NASDAQ Composite\n",
    "    '^DJI',      # Dow Jones Industrial Average\n",
    "    '^RUT',      # Russell 2000\n",
    "    '^W5000',    # Wilshire 5000\n",
    "    'XLF',       # Financials Sector (ETF)\n",
    "    'XLRE',      # Real Estate Sector (ETF)\n",
    "    'XLU',       # Utilities Sector (ETF)\n",
    "    'XLY',       # Consumer Discretionary Sector (ETF)\n",
    "    'XLP',       # Consumer Staples Sector (ETF)\n",
    "    'XLE',       # Energy Sector (ETF)\n",
    "    'XLV',       # Healthcare Sector (ETF)\n",
    "    'XLI',       # Industrials Sector (ETF)\n",
    "    'XLB',       # Materials Sector (ETF)\n",
    "    'XLK',       # Information Technology Sector (ETF)\n",
    "    'XLC',       # Communication Services Sector (ETF)\n",
    "    '^IRX',      # Three-month Treasury Bill Yield\n",
    "    '^TNX',      # Ten-year Treasury Yield\n",
    "]\n",
    "\n",
    "start_date = dates['Statement Date'].min() - pd.Timedelta(days=15)\n",
    "end_date = dates['Statement Date'].max() + pd.Timedelta(days=15)\n",
    "\n",
    "all_indices_data = {}\n",
    "for ticker in tickers:\n",
    "    #print(f\"Downloading data for {ticker}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data.columns = data.columns.get_level_values(0)\n",
    "    data['return'] = data['Close'].pct_change()\n",
    "    all_indices_data[ticker] = data[['return']].dropna()\n",
    "    #print(f\"Data for {ticker} downloaded.\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for index, row_fomc in dates.iterrows():\n",
    "    date = row_fomc['Statement Date']\n",
    "    document_type = row_fomc['document_type']\n",
    "    for ticker in tickers:\n",
    "        row = {'announcement_date': date, 'ticker': ticker, 'document_type': document_type} \n",
    "        for t in range(-15, 16):\n",
    "            target_date = date + pd.Timedelta(days=t)\n",
    "            if target_date in all_indices_data[ticker].index:\n",
    "                row[f'T{t:+}'] = all_indices_data[ticker].loc[target_date, 'return']\n",
    "            else:\n",
    "                row[f'T{t:+}'] = pd.NA\n",
    "        rows.append(row)\n",
    "\n",
    "statements_df = pd.DataFrame(rows)\n",
    "\n",
    "column_order = ['announcement_date', 'ticker', 'document_type'] + [f'T{t:+}' for t in range(-15, 16)]\n",
    "statements_df = statements_df[column_order]\n",
    "\n",
    "statements_df\n",
    "\n",
    "statements_df.to_csv('raw_data/statement_prices.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9bfc0b-3a67-430e-9e2f-0ab41df4098d",
   "metadata": {},
   "source": [
    "### Problem\n",
    "Need to figure out how to get the days for around the intermeeting dates now because \n",
    "the dates in the html links are the same as the fed statements for those, which would cause a problem \n",
    "when getting return data.\n",
    "\n",
    "How to get around this?\n",
    "Find a dataset with the dates of the intermeeting or make our own (just manually do it - would take an hour maybe)\n",
    "\n",
    "Ended up just manually doing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5325bd23-83a8-4969-aee9-4b10c03b0c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/fd_cpcmx35x03xwkvsfgw9kc0000gn/T/ipykernel_9312/3896584411.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dates['Intermeeting Date'] = pd.to_datetime(dates['Intermeeting Date'])\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dates = pd.read_csv('dates/dates_updated.csv')\n",
    "dates['Intermeeting Date'] = pd.to_datetime(dates['Intermeeting Date'])\n",
    "dates['document_type'] = 'intermeeting' \n",
    "\n",
    "tickers = [\n",
    "    '^GSPC',     # S&P 500\n",
    "    '^IXIC',     # NASDAQ Composite\n",
    "    '^DJI',      # Dow Jones Industrial Average\n",
    "    '^RUT',      # Russell 2000\n",
    "    '^W5000',    # Wilshire 5000\n",
    "    'XLF',       # Financials Sector (ETF)\n",
    "    'XLRE',      # Real Estate Sector (ETF)\n",
    "    'XLU',       # Utilities Sector (ETF)\n",
    "    'XLY',       # Consumer Discretionary Sector (ETF)\n",
    "    'XLP',       # Consumer Staples Sector (ETF)\n",
    "    'XLE',       # Energy Sector (ETF)\n",
    "    'XLV',       # Healthcare Sector (ETF)\n",
    "    'XLI',       # Industrials Sector (ETF)\n",
    "    'XLB',       # Materials Sector (ETF)\n",
    "    'XLK',       # Information Technology Sector (ETF)\n",
    "    'XLC',       # Communication Services Sector (ETF)\n",
    "    '^IRX',      # Three-month Treasury Bill Yield\n",
    "    '^TNX',      # Ten-year Treasury Yield\n",
    "]\n",
    "\n",
    "start_date = dates['Intermeeting Date'].min() - pd.Timedelta(days=15)\n",
    "end_date = dates['Intermeeting Date'].max() + pd.Timedelta(days=15)\n",
    "\n",
    "all_indices_data = {}\n",
    "for ticker in tickers:\n",
    "    #print(f\"Downloading data for {ticker}...\")\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data.columns = data.columns.get_level_values(0)\n",
    "    data['return'] = data['Close'].pct_change()\n",
    "    all_indices_data[ticker] = data[['return']].dropna()\n",
    "    #print(f\"Data for {ticker} downloaded.\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for index, row_fomc in dates.iterrows():\n",
    "    date = row_fomc['Intermeeting Date']\n",
    "    document_type = row_fomc['document_type']\n",
    "    for ticker in tickers:\n",
    "        row = {'announcement_date': date, 'ticker': ticker, 'document_type': document_type} \n",
    "        for t in range(-15, 16):\n",
    "            target_date = date + pd.Timedelta(days=t)\n",
    "            if target_date in all_indices_data[ticker].index:\n",
    "                row[f'T{t:+}'] = all_indices_data[ticker].loc[target_date, 'return']\n",
    "            else:\n",
    "                row[f'T{t:+}'] = pd.NA\n",
    "        rows.append(row)\n",
    "\n",
    "intermeeting_df = pd.DataFrame(rows)\n",
    "\n",
    "column_order = ['announcement_date', 'ticker', 'document_type'] + [f'T{t:+}' for t in range(-15, 16)]\n",
    "intermeeting_df = intermeeting_df[column_order]\n",
    "\n",
    "intermeeting_df\n",
    "\n",
    "intermeeting_df.to_csv('raw_data/intermeeting_prices.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028a6f6-49db-4f12-88fa-7a1ec438ffed",
   "metadata": {},
   "source": [
    "### Need to merge the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebd336c0-0f77-44d7-9d71-4a9398037c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([statements_df, intermeeting_df], ignore_index=True)\n",
    "combined_df = combined_df.dropna(subset=['announcement_date'])\n",
    "combined_df = combined_df.sort_values(by='announcement_date').reset_index(drop=True)\n",
    "combined_df['meeting_id'] = combined_df['announcement_date'].rank(method='dense').astype(int)\n",
    "combined_df = combined_df[['meeting_id'] + [col for col in combined_df.columns if col != 'meeting_id']]\n",
    "combined_df.to_csv('raw_data/combined_dates.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac91910b-6467-42e7-9e6c-fa9e33b1f3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>announcement_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>document_type</th>\n",
       "      <th>T-15</th>\n",
       "      <th>T-14</th>\n",
       "      <th>T-13</th>\n",
       "      <th>T-12</th>\n",
       "      <th>T-11</th>\n",
       "      <th>T-10</th>\n",
       "      <th>...</th>\n",
       "      <th>T+6</th>\n",
       "      <th>T+7</th>\n",
       "      <th>T+8</th>\n",
       "      <th>T+9</th>\n",
       "      <th>T+10</th>\n",
       "      <th>T+11</th>\n",
       "      <th>T+12</th>\n",
       "      <th>T+13</th>\n",
       "      <th>T+14</th>\n",
       "      <th>T+15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>statement</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>-0.002912</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>-0.020815</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>^TNX</td>\n",
       "      <td>statement</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>0.00342</td>\n",
       "      <td>0.00489</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>-0.001949</td>\n",
       "      <td>-0.005258</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.012385</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>-0.000763</td>\n",
       "      <td>0.00336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>^IRX</td>\n",
       "      <td>statement</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>-0.009346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>-0.005435</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.00365</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>XLC</td>\n",
       "      <td>statement</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>XLK</td>\n",
       "      <td>statement</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>-0.012443</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>-0.026573</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>-0.005154</td>\n",
       "      <td>0.022452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>^DJI</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.003116</td>\n",
       "      <td>-0.003653</td>\n",
       "      <td>-0.016922</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>-0.017329</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.024828</td>\n",
       "      <td>0.026632</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>-0.020405</td>\n",
       "      <td>-0.005307</td>\n",
       "      <td>-0.027019</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.030673</td>\n",
       "      <td>-0.00127</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.025515</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>^IRX</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>XLU</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>-0.015991</td>\n",
       "      <td>0.00663</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>-0.009011</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.023659</td>\n",
       "      <td>0.027262</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>408</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>^TNX</td>\n",
       "      <td>intermeeting</td>\n",
       "      <td>-0.005541</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>-0.026093</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009395</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>0.01262</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>-0.003632</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7398 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meeting_id announcement_date ticker document_type      T-15      T-14  \\\n",
       "0              1        2000-02-02  ^GSPC     statement      <NA>  0.000522   \n",
       "1              1        2000-02-02   ^TNX     statement      <NA> -0.003408   \n",
       "2              1        2000-02-02   ^IRX     statement      <NA>  0.022945   \n",
       "3              1        2000-02-02    XLC     statement      <NA>      <NA>   \n",
       "4              1        2000-02-02    XLK     statement      <NA>  0.001765   \n",
       "...          ...               ...    ...           ...       ...       ...   \n",
       "7393         408        2025-04-09   ^DJI  intermeeting  0.000098 -0.003116   \n",
       "7394         408        2025-04-09  ^IXIC  intermeeting  0.004578 -0.020405   \n",
       "7395         408        2025-04-09   ^IRX  intermeeting       0.0  0.001913   \n",
       "7396         408        2025-04-09    XLU  intermeeting -0.015991   0.00663   \n",
       "7397         408        2025-04-09   ^TNX  intermeeting -0.005541  0.007198   \n",
       "\n",
       "          T-13      T-12  T-11  T-10  ...       T+6       T+7       T+8  \\\n",
       "0    -0.007095 -0.002912  <NA>  <NA>  ...  0.012273 -0.020815  0.003627   \n",
       "1      0.00342   0.00489  <NA>  <NA>  ... -0.004826  0.010608 -0.001949   \n",
       "2    -0.009346       0.0  <NA>  <NA>  ...  0.009141 -0.005435  0.001822   \n",
       "3         <NA>      <NA>  <NA>  <NA>  ...      <NA>      <NA>      <NA>   \n",
       "4     0.005868  0.001167  <NA>  <NA>  ...  0.009132 -0.012443  0.023769   \n",
       "...        ...       ...   ...   ...  ...       ...       ...       ...   \n",
       "7393 -0.003653 -0.016922  <NA>  <NA>  ... -0.003845 -0.017329 -0.013289   \n",
       "7394 -0.005307 -0.027019  <NA>  <NA>  ... -0.000494 -0.030673  -0.00127   \n",
       "7395 -0.000477       0.0  <NA>  <NA>  ...  0.001192  0.001905 -0.000713   \n",
       "7396 -0.000258  0.007363  <NA>  <NA>  ... -0.000129 -0.009011  0.010262   \n",
       "7397  0.007146 -0.026093  <NA>  <NA>  ... -0.009395 -0.010178   0.01262   \n",
       "\n",
       "           T+9  T+10  T+11      T+12      T+13      T+14      T+15  \n",
       "0    -0.020969  <NA>  <NA>  0.002033  0.008713 -0.010256  0.000425  \n",
       "1    -0.005258  <NA>  <NA> -0.012385  0.001988 -0.000763   0.00336  \n",
       "2    -0.003636  <NA>  <NA>  -0.00365  0.021978 -0.005376  0.003604  \n",
       "3         <NA>  <NA>  <NA>      <NA>      <NA>      <NA>      <NA>  \n",
       "4    -0.026573  <NA>  <NA>  0.000574  0.002872 -0.005154  0.022452  \n",
       "...        ...   ...   ...       ...       ...       ...       ...  \n",
       "7393      <NA>  <NA>  <NA> -0.024828  0.026632  0.010707      <NA>  \n",
       "7394      <NA>  <NA>  <NA> -0.025515  0.027063  0.025007      <NA>  \n",
       "7395      <NA>  <NA>  <NA>  0.001189  0.000713 -0.001187      <NA>  \n",
       "7396      <NA>  <NA>  <NA> -0.023659  0.027262  0.004231      <NA>  \n",
       "7397      <NA>  <NA>  <NA>  0.016617 -0.003632 -0.000456      <NA>  \n",
       "\n",
       "[7398 rows x 35 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a034c8d-01c6-4dab-b5fa-be359273d5b1",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879dc84f-6ac8-42a5-bf0a-71e81e2aacea",
   "metadata": {},
   "source": [
    "I just copied the inputs file from the midterm so we can use the ML and LM dictionaries through that......\n",
    "\n",
    "Shouldn't be too difficult for that part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad49a0-b3d6-4983-a636-ccfd2f6dae44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcf7fd-c74a-4a7b-a1d9-3af5ad8fd322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71864766-75fd-4862-bd2a-a9c092620f09",
   "metadata": {},
   "source": [
    "Then we need to do the topic analysis as well......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229b378-ec08-4590-afe7-b3121ee7bc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22a562-53ed-4fab-80f4-43a26ed4e0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb79aa-8e72-4b98-95cf-f0f49a743aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bae1339-accc-4d4a-9d97-210d014774c7",
   "metadata": {},
   "source": [
    "## The tricky parts - Be working on this by tuesday or we gonna be in trouble "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4b728-1e6f-46f8-a443-212c3b29eb0c",
   "metadata": {},
   "source": [
    "### Chat GPT API integration to rank documents on bullish to bearish scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d8311-ca68-4151-8e71-5927859b42c5",
   "metadata": {},
   "source": [
    "### ChronoBERT - yikes "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
